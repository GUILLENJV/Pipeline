{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtCGUTmYEYvi6TJKSKK3Ti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GUILLENJV/Pipeline/blob/master/PS_6_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsimfFg6-fwV",
        "outputId": "f7dae12b-cd19-4c3d-ec8a-21e13e81a100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8 in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (24.3.7)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8) (1.62.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "F3GTGYlm_Cu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "metadata": {
        "id": "rruwnZU6-fk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY7LKsOJadq3",
        "outputId": "5fce85be-0daa-4531-af48-e1cfce2f579a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0mNly9gXgiF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "#import scikeras\n",
        "#from scikeras.wrappers import KerasRegressor\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import load_model\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFmNEZ3JZM4J",
        "outputId": "9fb8d704-cbd8-4ad9-f409-1158fefe2dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "sjiZWwjlZuSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sJA01KLhtOp",
        "outputId": "496bc98c-e16d-4454-e730-a3194471d45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# %%\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import eda\n",
        "import numpy as np\n",
        "import os\n",
        "# os.environ['HDF5_DISABLE_VERSION_CHECK']='2'\n",
        "from feature_models import create_model, FeatureCreation\n",
        "import pickle\n",
        "#from tensorflow.compat.v1.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.models import load_model\n",
        "import functools\n",
        "from sklearn.model_selection import train_test_split\n",
        "import graphs\n",
        "# %%\n",
        "st.set_page_config(\n",
        "    page_title=\"Predicting Real Estate Prices in Brazil\",\n",
        "    page_icon=\"🧙‍♂️\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "# Predicting Rental Prices in Brazil\n",
        "[![Star](https://img.shields.io/github/stars/arturlunardi/predict_rental_prices_streamlit?style=social)](https://github.com/arturlunardi/predict_rental_prices_streamlit)\n",
        "&nbsp[![Follow](https://img.shields.io/badge/medium-arturlunardi-follow?style=social&logo=medium)](https://arturlunardi.medium.com/)\n",
        "&nbsp[![Follow](https://img.shields.io/badge/Connect-follow?style=social&logo=linkedin)](https://www.linkedin.com/in/artur-lunardi-di-fante-393611194/)\n",
        "\"\"\"\n",
        "\n",
        "# ----------- Data -------------------\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def get_raw_data():\n",
        "    \"\"\"\n",
        "    This function return a pandas DataFrame with the raw data.\n",
        "    \"\"\"\n",
        "\n",
        "    raw_df = pd.read_csv(os.path.join(os.path.abspath(''), 'data', 'houses_to_rent_v2.csv'))\n",
        "    return raw_df\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def get_cleaned_data():\n",
        "    \"\"\"\n",
        "    This function return a pandas DataFrame with the cleaned data.\n",
        "    \"\"\"\n",
        "\n",
        "    clean_data = pd.read_csv(os.path.join(os.path.abspath(''), 'data', 'houses_to_rent_v2_fteng.csv'))\n",
        "    return clean_data\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def get_raw_eval_df():\n",
        "    \"\"\"\n",
        "    This function return a pandas DataFrame with the dataframe and the machine learning models along with it's metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    raw_eval_df = pd.read_csv(os.path.join(os.path.abspath(''), 'data', 'model_evaluation.csv'))\n",
        "    return raw_eval_df\n",
        "\n",
        "\n",
        "@st.cache(hash_funcs={pd.DataFrame: lambda x: x})\n",
        "def load_models_df(dataframe):\n",
        "    df_evaluated = dataframe.copy()\n",
        "    models_list = os.listdir(os.path.join(os.path.abspath(''), '/content/models'))\n",
        "    rep = {\"pipe\": \"model\", \"pickle\": \"h5\"}\n",
        "    for index, row in df_evaluated.iterrows():\n",
        "        # check if the file_name is in our models directory\n",
        "        if row['pipe_file_name'] in models_list:\n",
        "            # now, load the model.\n",
        "            with open(os.path.join(os.path.abspath(''), '/content/models', row['pipe_file_name']), 'rb') as fid:\n",
        "                model_trained = pickle.load(fid)\n",
        "\n",
        "            # for the keras model, we have to load the model separately and add into the pipeline or transformed target object.\n",
        "            if row['name'] == 'NeuralNetwork':\n",
        "                model_keras = load_model(os.path.join(os.path.abspath(''), '/content/models', functools.reduce(lambda a, kv: a.replace(*kv), rep.items(), row['pipe_file_name'])))\n",
        "                # check if the target transformer it is active\n",
        "                if row['custom_target']:\n",
        "                    # reconstruct the model inside a kerasregressor and add inside the transformed target object\n",
        "                    model_trained.regressor.set_params(model = KerasRegressor(build_fn=create_model, verbose=0))\n",
        "                    # add the keras model inside the pipeline object\n",
        "                    model_trained.regressor_.named_steps['model'].model = model_keras\n",
        "                else:\n",
        "                    model_trained.named_steps['model'].model = model_keras\n",
        "\n",
        "            df_evaluated.loc[index, 'model_trained'] = model_trained\n",
        "\n",
        "    # we have to transform our score column to bring it back to a python list\n",
        "    df_evaluated['all_scores_cv'] = df_evaluated['all_scores_cv'].apply(lambda x: [float(i) for i in x.strip('[]').split()])\n",
        "\n",
        "    return df_evaluated.sort_values(by='rmse_cv').reset_index(drop=True)\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def split(dataframe):\n",
        "    df = dataframe.copy()\n",
        "    x = df.drop(columns=['rent amount (R$)'], axis=1)\n",
        "    y = df['rent amount (R$)']\n",
        "    # check if the random state it is equal to when it was trained, this is very important.\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x,\n",
        "                                                        y,\n",
        "                                                        test_size=0.25,\n",
        "                                                        random_state=0)\n",
        "\n",
        "    return x, y, x_train, x_test, y_train, y_test\n",
        "\n",
        "raw_df = get_raw_data()\n",
        "clean_df = get_cleaned_data()\n",
        "raw_eval_df = get_raw_eval_df()\n",
        "eval_df = load_models_df(raw_eval_df)\n",
        "x, y, x_train, x_test, y_train, y_test = split(clean_df)\n",
        "\n",
        "# ----------- Global Sidebar ---------------\n",
        "\n",
        "condition = st.sidebar.selectbox(\n",
        "    \"Select the visualization\",\n",
        "    (\"Introduction\", \"EDA\", \"Model Prediction\", \"Model Evaluation\")\n",
        ")\n",
        "\n",
        "# ------------- Introduction ------------------------\n",
        "\n",
        "if condition == 'Introduction':\n",
        "    st.image(os.path.join(os.path.abspath(''), 'data', 'dataset-cover.jpg'))\n",
        "    st.subheader('About')\n",
        "\n",
        "    ## FALTA O CHECK ON GITHUB\n",
        "    st.write(\"\"\"\n",
        "    This application provides an overview of the brazilian_houses_to_rent dataset from Kaggle. It is a dataset that provides rent prices for real estate properties in Brazil.\n",
        "\n",
        "    The data were provided from this [source](https://www.kaggle.com/rubenssjr/brasilian-houses-to-rent).\n",
        "\n",
        "    You can check on the sidebar:\n",
        "    - EDA (Exploratory Data Analysis)\n",
        "    - Model Prediction\n",
        "    - Model Evaluation\n",
        "\n",
        "    The prediction are made regarding to the rent amount utilizing pre trained machine learning models.\n",
        "\n",
        "    All the operations in the dataset were already done and stored as csv files inside the data directory. If you want to check the code, go through the notebook directory in the [github repository](https://github.com/arturlunardi/predict_rental_prices_streamlit).\n",
        "    \"\"\")\n",
        "\n",
        "    st.subheader('Model Definition')\n",
        "\n",
        "    st.write(\"\"\"\n",
        "    The structure of the training it is to wrap the process around a scikit-learn Pipeline. There were 4 possible combinations and 5 models, resulting in 20 trained models.\n",
        "\n",
        "    The combinations are regarding to perform Feature Creation and/or Target Transformations in the dataset.\n",
        "\n",
        "    Models:\n",
        "    - Random Forest\n",
        "    - XGB\n",
        "    - Ridge\n",
        "    - LGBM\n",
        "    - Neural Network\n",
        "\n",
        "    Our main accuracy metric is RMSE. To enhance our model definition, we utilized Cross Validation and Random Search for hyperparameter tuning.\n",
        "    \"\"\")\n",
        "\n",
        "# ------------- EDA ------------------------\n",
        "\n",
        "elif condition == 'EDA':\n",
        "    type_of_data = st.radio(\n",
        "        \"Type of Data\",\n",
        "        ('Raw Data', 'Cleaned Data'),\n",
        "        help='Data source that will be displayed in the charts'\n",
        "    )\n",
        "\n",
        "    if type_of_data == 'Raw Data':\n",
        "        data = raw_df.copy()\n",
        "    else:\n",
        "        data = clean_df.copy()\n",
        "\n",
        "    with st.beta_container():\n",
        "        st.header('Descriptive Statistics\\n')\n",
        "        col1, col2 = st.beta_columns([1, 3])\n",
        "        col1.dataframe(eda.summary_table(data))\n",
        "        col2.dataframe(data.describe())\n",
        "\n",
        "    st.header('Data Visualization')\n",
        "\n",
        "    height, width, margin = 450, 1500, 10\n",
        "\n",
        "    st.subheader('Rent Amount Distribution')\n",
        "\n",
        "    select_city_eda = st.selectbox(\n",
        "        'Select the City',\n",
        "        ['All'] + [i for i in data['city'].unique()]\n",
        "    )\n",
        "\n",
        "    if select_city_eda == 'All':\n",
        "        fig = graphs.plot_histogram(data=data, x=\"rent amount (R$)\", nbins=50, height=height, width=width, margin=margin)\n",
        "    else:\n",
        "        fig = graphs.plot_histogram(\n",
        "            data = data.loc[data['city'] == select_city_eda], x=\"rent amount (R$)\", nbins=50, height=height, width=width, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Scatterplot')\n",
        "\n",
        "    select_numerical = st.selectbox(\n",
        "        'Select the Numerical Variable',\n",
        "        ['area', 'hoa (R$)', 'property tax (R$)', 'fire insurance (R$)']\n",
        "    )\n",
        "\n",
        "    fig = graphs.plot_scatter(data=data, x=select_numerical, y=\"rent amount (R$)\", height=height, width=width, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Categorical Graphs')\n",
        "\n",
        "    select_graph = st.radio(\n",
        "        'Select the Type of Graph',\n",
        "        ('Boxplot', 'Countplot')\n",
        "    )\n",
        "\n",
        "    select_variable = st.selectbox(\n",
        "        'Select the Variable',\n",
        "        [i for i in data.columns if data[i].dtype == object and i != 'floor']\n",
        "    )\n",
        "\n",
        "    if select_graph == 'Boxplot':\n",
        "        fig = graphs.plot_boxplot(data=data, x=select_variable, y=\"rent amount (R$)\", color=select_variable, height=height, width=width, margin=margin)\n",
        "    elif select_graph == 'Countplot':\n",
        "        fig = graphs.plot_countplot(data=data, x=select_variable, height=height, width=width, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Rent amount mean per Variable')\n",
        "\n",
        "    option = st.selectbox(\n",
        "        'Select the Column',\n",
        "        ('rooms', 'bathroom', 'parking spaces'),\n",
        "    )\n",
        "\n",
        "    fig = graphs.plot_bar(data=data.groupby(option).mean().reset_index(), x=option, y='rent amount (R$)', height=height, width=width, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Correlation Matrix')\n",
        "\n",
        "    corr_matrix = data.corr()\n",
        "\n",
        "    fig = graphs.plot_heatmap(corr_matrix=corr_matrix, height=height, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "\n",
        "elif condition == 'Model Prediction':\n",
        "\n",
        "    select_model_mpredict = st.sidebar.selectbox(\n",
        "        'Select the Model',\n",
        "        [i for i in eval_df['name'].unique()]\n",
        "    )\n",
        "\n",
        "    select_custom_features_mpredict = st.sidebar.select_slider(\n",
        "        'Create Custom Features?',\n",
        "        [False, True],\n",
        "        help='Feature Creation according to the FeatureCreation class in the load_models module'\n",
        "    )\n",
        "\n",
        "    select_custom_target_mpredict = st.sidebar.select_slider(\n",
        "        'Perform Target Transformation?',\n",
        "        [False, True],\n",
        "        help='Perform a logarithm transformation in the target variable'\n",
        "    )\n",
        "\n",
        "    select_city = st.sidebar.selectbox(\n",
        "        'Select the City',\n",
        "        clean_df['city'].value_counts().index\n",
        "    )\n",
        "\n",
        "    select_area = st.sidebar.number_input(\n",
        "        'Select the value of Area',\n",
        "        help='The value must be in square meters (m²)',\n",
        "        min_value=1,\n",
        "    )\n",
        "\n",
        "    select_rooms = st.sidebar.number_input(\n",
        "        'Select the number of Rooms',\n",
        "        min_value=1,\n",
        "    )\n",
        "\n",
        "    select_bathrooms = st.sidebar.number_input(\n",
        "        'Select the number of Bathrooms',\n",
        "        min_value=1,\n",
        "    )\n",
        "\n",
        "    select_parking_spaces = st.sidebar.number_input(\n",
        "        'Select the number of Parking Spaces',\n",
        "        min_value=0,\n",
        "    )\n",
        "\n",
        "    select_animal = st.sidebar.select_slider(\n",
        "        'Accept Animals?',\n",
        "        ['acept', 'not acept']\n",
        "    )\n",
        "\n",
        "    select_furniture = st.sidebar.select_slider(\n",
        "        'It is furnished',\n",
        "        ['furnished', 'not furnished']\n",
        "    )\n",
        "\n",
        "    select_hoa = st.sidebar.number_input(\n",
        "        'Select the value of Hoa',\n",
        "        help='The values must be in Reais (R$)',\n",
        "        min_value=0,\n",
        "    )\n",
        "\n",
        "    select_property_tax = st.sidebar.number_input(\n",
        "        'Select the value of Property Tax',\n",
        "        help='The values must be in Reais (R$)',\n",
        "        min_value=0,\n",
        "    )\n",
        "\n",
        "    select_fire_insurance = st.sidebar.number_input(\n",
        "        'Select the value of Fire Insurance',\n",
        "        help='The values must be in Reais (R$)',\n",
        "        min_value=0,\n",
        "    )\n",
        "\n",
        "    predict_array = [select_city, select_area, select_rooms, select_bathrooms, select_parking_spaces, select_animal, select_furniture, select_hoa, select_property_tax, select_fire_insurance]\n",
        "\n",
        "    model_trained_mpredict = eval_df.loc[(eval_df['name'] == select_model_mpredict) & (eval_df['custom_features'] == select_custom_features_mpredict) & (eval_df['custom_target'] == select_custom_target_mpredict)]['model_trained'].iloc[0]\n",
        "\n",
        "    value_to_predict = pd.DataFrame(\n",
        "        [predict_array], columns=clean_df.drop(columns='rent amount (R$)').columns\n",
        "    )\n",
        "\n",
        "    st.subheader('Available Models')\n",
        "\n",
        "    st.dataframe(eval_df.drop(columns=['all_scores_cv', 'pipe_file_name', 'model_trained']))\n",
        "\n",
        "    if st.button('Predict', help='Be certain to check the parameters on the sidebar'):\n",
        "        predicted_value = model_trained_mpredict.predict(value_to_predict)\n",
        "        st.success(f'The predicted value is R$ {round(predicted_value[0], 2)}')\n",
        "\n",
        "        with st.beta_expander(\"Model Parameters\"):\n",
        "            st.write(f\"The model chosen was {select_model_mpredict}. \\n\\n Parameters:\", eval(eval_df.loc[(eval_df['name'] == select_model_mpredict) & (eval_df['custom_features'] == select_custom_features_mpredict) & (eval_df['custom_target'] == select_custom_target_mpredict)]['params'].iloc[0])[0])\n",
        "\n",
        "\n",
        "# -------------------------------------------\n",
        "\n",
        "elif condition == 'Model Evaluation':\n",
        "    st.subheader('Available Models')\n",
        "\n",
        "    st.dataframe(eval_df.drop(columns=['all_scores_cv', 'pipe_file_name', 'model_trained']))\n",
        "\n",
        "    select_model_meval = st.sidebar.selectbox(\n",
        "        'Select the Model',\n",
        "        [i for i in eval_df['name'].unique()]\n",
        "    )\n",
        "\n",
        "    select_custom_features_meval = st.sidebar.select_slider(\n",
        "        'Create Custom Features?',\n",
        "        [False, True]\n",
        "    )\n",
        "\n",
        "    select_custom_target_meval = st.sidebar.select_slider(\n",
        "        'Perform Target Transformation?',\n",
        "        [False, True]\n",
        "    )\n",
        "\n",
        "    model_trained_meval = eval_df.loc[(eval_df['name'] == select_model_meval) & (eval_df['custom_features'] == select_custom_features_meval) & (eval_df['custom_target'] == select_custom_target_meval)]['model_trained'].iloc[0]\n",
        "\n",
        "# -------------- figs -----------------\n",
        "\n",
        "    height, width, margin = 450, 1500, 30\n",
        "\n",
        "    st.subheader('Distribution of the Target Variable')\n",
        "\n",
        "    fig = graphs.plot_distplot(\n",
        "        y_real=y_test,\n",
        "        y_predict=model_trained_meval.predict(x_test),\n",
        "        height=height,\n",
        "        width=width,\n",
        "        margin=margin,\n",
        "        title_text='Predicted and Real Value'\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Distribution of the Residuals')\n",
        "\n",
        "    # predict the values of the entire data\n",
        "    prediction = model_trained_meval.predict(x)\n",
        "    # calculate the residual\n",
        "    resid = prediction - y\n",
        "\n",
        "    # create a copy to not alter the original data\n",
        "    df_plot = clean_df.copy()\n",
        "    # create a column to identify the data regarding to train or test\n",
        "    df_plot['split'] = 'train'\n",
        "    df_plot.loc[x_test.index, 'split'] = 'test'\n",
        "    df_plot['prediction'] = prediction\n",
        "    df_plot['resid'] = resid\n",
        "\n",
        "    # plot the residual plot with the histograms\n",
        "    fig = graphs.plot_scatter(data=df_plot, x='prediction', y='resid', residual=True, height=height, width=width, margin=margin, title_text='Residuals per Split')\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader('Boxplot of RMSE in Cross Validation')\n",
        "\n",
        "    fig = graphs.plot_boxplot(data=eval_df, x=None, y=None, model_name=select_model_meval, custom_feature=select_custom_features_meval, custom_target=select_custom_target_meval, single_box=True, title_text='Cross Validation with 5 Folds', height=height, width=width, margin=margin)\n",
        "\n",
        "    st.plotly_chart(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iShdfmK1Z5fG",
        "outputId": "ea8c6521-d02e-46e8-d573-e42b16d3b450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eda.py\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def summary_table(df):\n",
        "    \"\"\"\n",
        "    Return a summary table with the descriptive statistics about the dataframe.\n",
        "    \"\"\"\n",
        "\n",
        "    summary = {\n",
        "    \"Number of Variables\": [len(df.columns)],\n",
        "    \"Number of Observations\": [df.shape[0]],\n",
        "    \"Missing Cells\": [df.isnull().sum().sum()],\n",
        "    \"Missing Cells (%)\": [round(df.isnull().sum().sum() / df.shape[0] * 100, 2)],\n",
        "    \"Duplicated Rows\": [df.duplicated().sum()],\n",
        "    \"Duplicated Rows (%)\": [round(df.duplicated().sum() / df.shape[0] * 100, 2)],\n",
        "    \"Categorical Variables\": [len([i for i in df.columns if df[i].dtype==object])],\n",
        "    \"Numerical Variables\": [len([i for i in df.columns if df[i].dtype!=object])],\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(summary).T.rename(columns={0: 'Values'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7pEtUcyavnW",
        "outputId": "b4e6ebb0-2e41-485d-faa1-412037cbe1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feature_models.py\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "def create_model(optimizer='adam', dropout=0.2, activation='relu', kernel_initializer='normal'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units = 15, activation = activation, input_dim = 15, kernel_initializer=kernel_initializer))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = 11, activation = activation))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = 1, activation = activation))\n",
        "\n",
        "    model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class FeatureCreation(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # print('FeatureCreation initialized')\n",
        "        pass\n",
        "\n",
        "    # For the fit method, we will pass the parameter x. This is our independent variables.\n",
        "    # This fit method will be called when we fit the pipeline.\n",
        "    def fit(self, x, y=None):\n",
        "        # print('Fit FeatureCreation called')\n",
        "        return self\n",
        "\n",
        "    # Here, we will perform all of our transformations. For creating features automatic, we could create parameters in the class and pass the column names to them.\n",
        "    # But in this case, since it's for this dataset specific, we will perform transformations in the column names directly into the fit method.\n",
        "    # The transform method is called when we fit and when we predict using the Pipeline. And that's make sense, since we need to create our feature when we will train and when we will predict.\n",
        "    def transform(self, x, y=None):\n",
        "        # print('Transform FeatureCreation called')\n",
        "        # creating a copy to avoid changes to the original dataset\n",
        "        x_ = x.copy()\n",
        "        # print(f'Before Transformation: {x_.shape}')\n",
        "        # and now, we create everyone of our features.\n",
        "        # Area power of two\n",
        "        x_['area2'] = x_['area'] ** 2\n",
        "        # The ratio between area and rooms\n",
        "        x_['area/room'] = x_['area'] / x_['rooms']\n",
        "        # The ratio between area and bathroom\n",
        "        x_['area/bathroom'] = x_['area'] / x_['bathroom']\n",
        "        # the sum of rooms and bathrooms\n",
        "        x_['rooms+bathroom'] = x_['rooms'] + x_['bathroom']\n",
        "        # the product between rooms and bathrooms\n",
        "        x_['rooms*bathroom'] = x_['rooms'] * x_['bathroom']\n",
        "        # the ratio between rooms and bathrooms\n",
        "        x_['rooms/bathroom'] = x_['rooms'] / x_['bathroom']\n",
        "        # the product between hoa and property tax\n",
        "        x_['hoa*property tax'] = x_['hoa (R$)'] * x_['property tax (R$)']\n",
        "        # print(f'After Transformation: {x_.shape}')\n",
        "        return x_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eQXnBdaxX0",
        "outputId": "657c6d0d-373c-4c6d-9b50-cc79ecfcacc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feature_models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile graphs.py\n",
        "import streamlit as st\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_histogram(data, x, nbins, height, width, margin, title_text=None):\n",
        "    fig = px.histogram(data, x=x, nbins=nbins)\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_scatter(data, x, y, height, width, margin, residual=False, title_text=None):\n",
        "    if residual:\n",
        "        fig = px.scatter(\n",
        "        data, x=x, y=y,\n",
        "        marginal_x='histogram', marginal_y='histogram',\n",
        "        color='split', trendline='ols', opacity=.5\n",
        "        )\n",
        "\n",
        "        # add an annotation with the train R2\n",
        "        fig.add_annotation(\n",
        "                    xref=\"paper\",\n",
        "                    yref=\"paper\",\n",
        "                    x=0.73,\n",
        "                    y=0.98,\n",
        "                    text=f\"Train R²: {round(r2_score(data.loc[data['split'] == 'train']['rent amount (R$)'], data.loc[data['split'] == 'train']['prediction']), 3)}\",\n",
        "                    bordercolor=\"#c7c7c7\",\n",
        "                    borderwidth=2,\n",
        "                    borderpad=4,\n",
        "                    bgcolor=\"red\",\n",
        "                    opacity=0.8,\n",
        "                    showarrow=False,\n",
        "                    font=dict(\n",
        "                        family=\"Courier New, monospace\",\n",
        "                        size=12,\n",
        "                        color=\"#ffffff\"\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        # add an annotation with the test R2\n",
        "        fig.add_annotation(\n",
        "                    xref=\"paper\",\n",
        "                    yref=\"paper\",\n",
        "                    x=0.57,\n",
        "                    y=0.98,\n",
        "                    text=f\"Test R²: {round(r2_score(data.loc[data['split'] == 'test']['rent amount (R$)'], data.loc[data['split'] == 'test']['prediction']), 3)}\",\n",
        "                    bordercolor=\"#c7c7c7\",\n",
        "                    borderwidth=2,\n",
        "                    borderpad=4,\n",
        "                    bgcolor=\"blue\",\n",
        "                    opacity=0.8,\n",
        "                    showarrow=False,\n",
        "                    font=dict(\n",
        "                        family=\"Courier New, monospace\",\n",
        "                        size=12,\n",
        "                        color=\"#ffffff\"\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        # add an annotation with the train RMSE\n",
        "        fig.add_annotation(\n",
        "                    xref=\"paper\",\n",
        "                    yref=\"paper\",\n",
        "                    x=0.73,\n",
        "                    y=0.89,\n",
        "                    text=f\"Train RMSE: {round(mean_squared_error(data.loc[data['split'] == 'train']['rent amount (R$)'], data.loc[data['split'] == 'train']['prediction'], squared=False), 2)}\",\n",
        "                    bordercolor=\"#c7c7c7\",\n",
        "                    borderwidth=2,\n",
        "                    borderpad=4,\n",
        "                    bgcolor=\"red\",\n",
        "                    opacity=0.8,\n",
        "                    showarrow=False,\n",
        "                    font=dict(\n",
        "                        family=\"Courier New, monospace\",\n",
        "                        size=12,\n",
        "                        color=\"#ffffff\"\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        # add an annotation with the test RMSE\n",
        "        fig.add_annotation(\n",
        "                    xref=\"paper\",\n",
        "                    yref=\"paper\",\n",
        "                    x=0.56,\n",
        "                    y=0.89,\n",
        "                    text=f\"Test RMSE: {round(mean_squared_error(data.loc[data['split'] == 'test']['rent amount (R$)'], data.loc[data['split'] == 'test']['prediction'], squared=False), 2)}\",\n",
        "                    bordercolor=\"#c7c7c7\",\n",
        "                    borderwidth=2,\n",
        "                    borderpad=4,\n",
        "                    bgcolor=\"blue\",\n",
        "                    opacity=0.8,\n",
        "                    showarrow=False,\n",
        "                    font=dict(\n",
        "                        family=\"Courier New, monospace\",\n",
        "                        size=12,\n",
        "                        color=\"#ffffff\"\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "\n",
        "    else:\n",
        "        fig = px.scatter(data, x=x, y=y)\n",
        "\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache(hash_funcs={pd.DataFrame: lambda x: x})\n",
        "def plot_boxplot(data, x, y, height, width, margin, color=None, single_box=False, model_name=None, custom_feature=None, custom_target=None, title_text=None):\n",
        "    if single_box:\n",
        "        fig = go.Figure(\n",
        "        go.Box(\n",
        "            y = data.loc[(data['name'] == model_name) & (data['custom_features'] == custom_feature) & (data['custom_target'] == custom_target)]['all_scores_cv'].iloc[0],\n",
        "            name = model_name,\n",
        "            marker_color='darkblue',\n",
        "            boxpoints='all',\n",
        "            jitter=0.3,\n",
        "            boxmean=True\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        fig = px.box(data, x=x, y=y, color=color)\n",
        "\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_countplot(data, x, height, width, margin, title_text=None):\n",
        "    fig = px.histogram(data, x=x, color=x)\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_heatmap(corr_matrix, height, margin, title_text=None):\n",
        "    fig = go.Figure(\n",
        "        go.Heatmap(\n",
        "        z=corr_matrix.values,\n",
        "        x=corr_matrix.index.values,\n",
        "        y=corr_matrix.columns.values,\n",
        "        colorscale='RdBu_R',\n",
        "        zmax=1,\n",
        "        zmin=-1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.update_layout(bargap=0.05, height=height, width=700, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_distplot(y_real, y_predict, height, width, margin, title_text=None):\n",
        "    fig = ff.create_distplot(\n",
        "    [y_real, y_predict],\n",
        "    ['Real', 'Predicted'],\n",
        "    bin_size=150,\n",
        "    # show_hist=False\n",
        "    )\n",
        "\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "@st.cache\n",
        "def plot_bar(data, x, y, height, width, margin, title_text=None):\n",
        "    fig = px.bar(data, x=x, y=y, color=x)\n",
        "\n",
        "    fig.update_layout(bargap=0.05, height=height, width=width, title_text=title_text, margin=dict(t=margin,\n",
        "                                                                                                  b=margin\n",
        "                                                                                                )\n",
        "    )\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Na8Rs0Jaxld",
        "outputId": "f8f12f8e-6085-415b-c2e1-6fe503d71873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting graphs.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRCzG1x8bd7M",
        "outputId": "6a6ee078-bf71-4412-e8d1-8eed1b952672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.231.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "pVnnqFxybeCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}